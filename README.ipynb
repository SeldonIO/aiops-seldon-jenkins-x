{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A practical guide to MLOps with Seldon Core and Jenkins X\n",
    "\n",
    "This tutorial provides an end-to-end tutorial that shows you how to build you MLOps pipeline with Seldon Core and Jenkins X:\n",
    "\n",
    "* Seldon Core is a machine learning deployment & orchestration engine in Kubernetes\n",
    "* Jenkins X provides automated CI+CD for Kubernetes with Preview Environments on Pull Requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuitive explanation\n",
    "\n",
    "Before we proceed, we want to understand what we will be trying to achieve. \n",
    "\n",
    "And what better way of doing this than by diving into an architectural diagram.\n",
    "\n",
    "[TODO ARCHITECTURE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "* A Kubernetes cluster running v1.13+ (this was run using GKE)\n",
    "* The [jx CLI](https://github.com/jenkins-x/jx/) version 2.0.916\n",
    "* Jenkins-X installed in your cluster (you can set it up with the [jx boot tutorial](https://jenkins-x.io/docs/getting-started/setup/boot/))\n",
    "* Seldon Core [v0.5.0 installed]() in your cluster\n",
    "\n",
    "Once you set everything up, we'll be ready to kick off ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up repo\n",
    "\n",
    "Now we want to start setting up our repo. For this we will create the following structure:\n",
    "\n",
    "* `jenkins-x.yml` - File specifying the CI / CD steps \n",
    "* `Makefile` - Commands to build and test model\n",
    "* `README.(md|ipynb)` - This file!\n",
    "* `gitops/` - Folder containing the state of our production cluster\n",
    "* `src`\n",
    "    * `ModelName.py` - Model server wrapper file\n",
    "    * `test_ModelName.py` - Unit test for model server\n",
    "    * `requirements-dev.txt` - Requirements for testing\n",
    "    * `requirements.txt` - Requiremnets for prod\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a model locally\n",
    "\n",
    "Let's have a look at the model we're using for text classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements-dev.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements-dev.txt\n",
    "scikit-learn==0.20.1\n",
    "pytest==5.1.1\n",
    "joblib==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requiremnets-dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(\n",
    "    subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(\n",
    "    subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "# Printing the top 3 newstories\n",
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTENT:\n",
      "Subject: Re: HELP for Kidney Stones ..............\n",
      "Organization: The Avant-Garde of the Now, Ltd.\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: ucsd.edu\n",
      "\n",
      "As I recall from my bout with kidney stones, there isn't \n",
      "\n",
      "-----------\n",
      "\n",
      "PREDICTED CLASS: comp.graphics\n"
     ]
    }
   ],
   "source": [
    "# Let's try one\n",
    "idx = 0\n",
    "print(f\"CONTENT:{twenty_test.data[idx][35:230]}\\n\\n-----------\\n\")\n",
    "print(f\"PREDICTED CLASS: {categories[twenty_test.target[idx]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "print(f\"Accuracy: {np.mean(predicted == twenty_test.target):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model\n",
    "\n",
    "Now we want to be able to deploy the model we just trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(text_clf, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://news_classifier/...\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb gs://news_classifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  4.4 MiB/  4.4 MiB]                                                \n",
      "Operation completed over 1 objects/4.4 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp model.joblib gs://news_classifier/model/model.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated ACL on gs://news_classifier/model\n",
      "Updated ACL on gs://news_classifier/model.joblib\n",
      "Updated ACL on gs://news_classifier/model/model.joblib\n"
     ]
    }
   ],
   "source": [
    "!gsutil acl ch -r -u AllUsers:R gs://news_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/SklearnServer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/SklearnServer.py\n",
    "\n",
    "import joblib, logging\n",
    "from seldon_core.storage import Storage\n",
    "\n",
    "class SklearnServer:\n",
    "    def __init__(self, model_uri):\n",
    "        output_dir = Storage.download(model_uri)\n",
    "        self._model = joblib.load(f\"{output_dir}/model.joblib\")\n",
    "\n",
    "    def predict(self, data, feature_names=[], metadata={}):\n",
    "        logging.info(data)\n",
    "\n",
    "        prediction = self._model.predict(data)\n",
    "\n",
    "        logging.info(prediction)\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/requirements.txt\n",
    "scikit-learn==0.20.1\n",
    "joblib==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/seldon_model.conf\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/seldon_model.conf\n",
    "MODEL_NAME=SklearnServer\n",
    "API_TYPE=REST\n",
    "SERVICE_TYPE=MODEL\n",
    "PERSISTENCE=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "---> Installing dependencies ...\n",
      "Looking in links: /whl\n",
      "Collecting scikit-learn==0.20.1 (from -r requirements.txt (line 1))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/10/26/d04320c3edf2d59b1fcd0720b46753d4d603a76e68d8ad10a9b92ab06db2/scikit_learn-0.20.1-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
      "Collecting joblib==0.13.2 (from -r requirements.txt (line 2))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/site-packages (from scikit-learn==0.20.1->-r requirements.txt (line 1)) (1.17.2)\n",
      "Collecting scipy>=0.13.3 (from scikit-learn==0.20.1->-r requirements.txt (line 1))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/29/50/a552a5aff252ae915f522e44642bb49a7b7b31677f9580cfd11bcc869976/scipy-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
      "Installing collected packages: scipy, scikit-learn, joblib\n",
      "Successfully installed joblib-0.13.2 scikit-learn-0.20.1 scipy-1.3.1\n",
      "WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "WARNING: You are using pip version 19.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "SELDON_BASE_WRAPPER=\"seldonio/seldon-core-s2i-python36:0.12\"\n",
    "s2i build src/. $SELDON_BASE_WRAPPER sklearn-server:0.1 \\\n",
    "    --environment-file src/seldon_model.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "YOUR_DOCKER_USERNAME=\"axsauze\"\n",
    "\n",
    "docker tag sklearn-server:0.1 $YOUR_DOCKER_USERNAME/sklearn-server:0.1\n",
    "docker push $YOUR_DOCKER_USERNAME/sklearn-server:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p gitops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gitops/test_deployment.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile gitops/test_deployment.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: news-classifier-server\n",
    "  namespace: default\n",
    "  creationTimestamp: \n",
    "spec:\n",
    "  name: news-classifier-server\n",
    "  predictors:\n",
    "  - name: default\n",
    "    graph:\n",
    "      name: news-classifier-server-processor\n",
    "      endpoint:\n",
    "        type: REST\n",
    "      type: MODEL\n",
    "      children: []\n",
    "      parameters:\n",
    "      - name: model_uri\n",
    "        type: STRING\n",
    "        value: \"gs://news_classifier/model/\"\n",
    "    componentSpecs:\n",
    "    - metadata:\n",
    "        creationTimestamp: '2019-10-12T16:00:00Z'\n",
    "      spec:\n",
    "        containers:\n",
    "        - image: axsauze/sklearn-server:0.1\n",
    "          name: news-classifier-server-processor\n",
    "          env:\n",
    "          - name: SELDON_LOG_LEVEL\n",
    "            value: DEBUG\n",
    "        terminationGracePeriodSeconds: 1\n",
    "    replicas: 1\n",
    "    engineResources: {}\n",
    "    svcOrchSpec: {}\n",
    "    traffic: 100\n",
    "    explainer:\n",
    "      containerSpec:\n",
    "        name: ''\n",
    "        resources: {}\n",
    "  annotations:\n",
    "    seldon.io/engine-seldon-log-messages-externally: 'true'\n",
    "status: {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/news-classifier-server created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f gitops/test_deployment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ndarray {\n",
       "  values {\n",
       "    number_value: 2.0\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "import numpy as np\n",
    "\n",
    "url = !kubectl get svc ambassador -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'\n",
    "\n",
    "sc = SeldonClient(\n",
    "    gateway=\"ambassador\", \n",
    "    gateway_endpoint=\"localhost:80\",\n",
    "    deployment_name=\"news-classifier-server\",\n",
    "    payload_type=\"ndarray\",\n",
    "    namespace=\"default\",\n",
    "    transport=\"rest\")\n",
    "\n",
    "response = sc.predict(data=np.array([twenty_test.data[0]]))\n",
    "\n",
    "response.response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"meta\": {\n",
      "    \"puid\": \"so6n21pkf70fm66eka28lc63cr\",\n",
      "    \"tags\": {\n",
      "    },\n",
      "    \"routing\": {\n",
      "    },\n",
      "    \"requestPath\": {\n",
      "      \"news-classifier-server-processor\": \"axsauze/sklearn-server:0.1\"\n",
      "    },\n",
      "    \"metrics\": []\n",
      "  },\n",
      "  \"data\": {\n",
      "    \"names\": [],\n",
      "    \"ndarray\": [2.0]\n",
      "  }\n",
      "}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   350  100   278  100    72   7942   2057 --:--:-- --:--:-- --:--:-- 10294\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST -H 'Content-Type: application/json' \\\n",
    "     -d \"{'data': {'names': ['text'], 'ndarray': ['Hello world this is a test']}}\" \\\n",
    "    http://localhost/seldon/default/news-classifier-server/api/v0.1/predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"news-classifier-server\" deleted\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f gitops/test_deployment.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up CI before CD\n",
    "\n",
    "We have now separated our model development into two chunks: \n",
    "\n",
    "* The first one involves the creation of a model serve, and the second one involves the CI of the model server, and the second involves the deployment of models that create the model.\n",
    "\n",
    "\n",
    "## Using the Jenkins X pipeline\n",
    "\n",
    "In order to do this we will be able to first run some tests and the push to the docker repo.\n",
    "\n",
    "For this we will be leveraging the Jenkins X file, we'll first start with a simple file that just runs the tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing jenkins-x.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile jenkins-x.yml\n",
    "buildPack: none\n",
    "pipelineConfig:\n",
    "  pipelines:\n",
    "    release:\n",
    "      pipeline:\n",
    "        agent:\n",
    "          image: seldonio/core-builder:0.4\n",
    "        stages:\n",
    "        - name: build-and-test\n",
    "          parallel:\n",
    "          - name: test-sklearn-server\n",
    "            steps:\n",
    "            - name: run-tests\n",
    "              command: make\n",
    "              args:\n",
    "              - install_dev\n",
    "              - test\n",
    "    pullRequest:\n",
    "      pipeline:\n",
    "        agent:\n",
    "          image: seldonio/core-builder:0.4\n",
    "        stages:\n",
    "        - name: build-and-test\n",
    "          parallel:\n",
    "          - name: test-sklearn-server\n",
    "            steps:\n",
    "            - name: run-tests\n",
    "              command: make\n",
    "              args:\n",
    "              - install_dev\n",
    "              - test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to import the jenkins project. \n",
    "\n",
    "For this we need to make sure that you have pushed this repository into a github repo which the Jenkins Bot already has permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jx import --no-draft=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can actually see that when the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
